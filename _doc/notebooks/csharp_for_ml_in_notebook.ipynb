{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Command line for ML.net\n",
        "\n",
        "[ML.net](https://github.com/dotnet/machinelearning) hides a command line available through DLL Microsoft.ML.Tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n)\n",
              "        a += \"    \";\n",
              "    return a;\n",
              "}\n",
              "// look up into all sections and builds an automated menu //\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    var format_open = 0;\n",
              "    for (i = 0; i <= llast; i++)\n",
              "        tags.push(\"h\" + i);\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null) {\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
              "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
              "        }\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += end_format + \"</ul>\\n\";\n",
              "            format_open -= 1;\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2);\n",
              "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "        format_open += 1;\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += end_format + \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "\n",
              "    while (format_open > 0) {\n",
              "        text_menu += end_format;\n",
              "        format_open -= 1;\n",
              "    }\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
              "    var send = \"\";\n",
              "    var begin_format = '<li>';\n",
              "    var end_format = '</li>';\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
              "       begin_format, end_format);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We add magic command ``%%maml``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext csharpyml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Maml help\n",
        "\n",
        "An example on how to get help."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%maml -q\n",
        "\n",
        "?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help for Command: 'TrainTest'\n",
            "\n",
            "Summary:\n",
            "   Trains a predictor using the train file and then scores and evaluates the predictor using the test file.\n",
            "\n",
            "testFile=<string>                     The test data file (short form test)\n",
            "trainer=<name>{<options>}             Trainer to use Default value:'AveragedPerceptron' (short form tr)\n",
            "scorer=<name>{<options>}              Scorer to use\n",
            "evaluator=<name>{<options>}           Evaluator to use (short form eval)\n",
            "summaryFilename=<string>              Results summary filename (short form sf)\n",
            "featureColumn=<string>                Column to use for features Default value:'Features' (short form feat)\n",
            "labelColumn=<string>                  Column to use for labels Default value:'Label' (short form lab)\n",
            "weightColumn=<string>                 Column to use for example weight Default value:'Weight' (short form weight)\n",
            "groupColumn=<string>                  Column to use for grouping Default value:'GroupId' (short form group)\n",
            "nameColumn=<string>                   Name column name Default value:'Name' (short form name)\n",
            "customColumn[<tag>]=<string>          Columns with custom kinds declared through key assignments, e.g., col[Kind]=Name\n",
            "                                      to assign column named 'Name' kind 'Kind' (short form col)\n",
            "normalizeFeatures=[No|Warn|Auto|Yes]  Normalize option for the feature column Default value:'Auto' (short form norm)\n",
            "validationFile=<string>               The validation data file (short form valid)\n",
            "cacheData=[+|-]                       Whether we should cache input training data (short form cache)\n",
            "calibrator=<name>{<options>}          Output calibrator Default value:'PlattCalibration' (short form cali)\n",
            "maxCalibrationExamples=<int>          Number of instances to train the calibrator Default value:'1000000000' (short\n",
            "                                      form numcali)\n",
            "outputDataFile=<string>               File to save per-instance predictions and metrics to (short form dout)\n",
            "continueTrain=[+|-]                   Whether we should load predictor from input model and use it as the initial model\n",
            "                                      state Default value:'-' (short form cont)\n",
            "loader=<name>{<options>}              The data loader\n",
            "dataFile=<string>                     The data file (short form data)\n",
            "outputModelFile=<string>              Model file to save (short form out)\n",
            "inputModelFile=<string>               Model file to load (short form in)\n",
            "loadTransforms=[+|-]                  Load transforms from model file? (short form loadTrans)\n",
            "randomSeed=<int>                      Random seed (short form seed)\n",
            "parallel=<int>                        Desired degree of parallelism in the data pipeline (short form n)\n",
            "transform[<tag>]=<name>{<options>}    Transform (short form xf)\n"
          ]
        }
      ],
      "source": [
        "%%maml\n",
        "\n",
        "? traintest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available components for kind 'Trainer':\n",
            "  AveragedPerceptron: Averaged Perceptron\n",
            "    Aliases: avgper, ap\n",
            "  BinaryClassificationGamTrainer: Generalized Additive Model for Binary Classification\n",
            "    Aliases: gam\n",
            "  BinarySGD: Hogwild SGD (binary)\n",
            "    Aliases: sgd\n",
            "  FastForestClassification: Fast Forest Classification\n",
            "    Aliases: FastForest, ff, ffc\n",
            "  FastForestRegression: Fast Forest Regression\n",
            "    Aliases: ffr\n",
            "  FastTreeBinaryClassification: FastTree (Boosted Trees) Classification\n",
            "    Aliases: FastTreeClassification, FastTree, ft, ftc, FastRankBinaryClassification, FastRankBinaryClassificationWrapper, FastRankClassification, fr, btc, frc, fastrank, fastrankwrapper\n",
            "  FastTreeRanking: FastTree (Boosted Trees) Ranking\n",
            "    Aliases: ftrank, FastRankRanking, FastRankRankingWrapper, rank, frrank, btrank\n",
            "  FastTreeRegression: FastTree (Boosted Trees) Regression\n",
            "    Aliases: ftr, FastRankRegression, FastRankRegressionWrapper, frr, btr\n",
            "  FastTreeTweedieRegression: FastTree (Boosted Trees) Tweedie Regression\n",
            "    Aliases: fttweedie\n",
            "  KMeansPlusPlus: KMeans++ Clustering\n",
            "    Aliases: KM, KMeans\n",
            "  LinearSVM: SVM (Pegasos-Linear)\n",
            "    Aliases: svm\n",
            "  LogisticRegression: Logistic Regression\n",
            "    Aliases: lr, logisticregressionwrapper\n",
            "  MultiClassLogisticRegression: Multi-class Logistic Regression\n",
            "    Aliases: MulticlassLogisticRegressionPredictorNew, mlr, multilr\n",
            "  MultiClassNaiveBayes: Multiclass Naive Bayes\n",
            "    Aliases: MNB\n",
            "  OLSLinearRegression: Ordinary Least Squares (Regression)\n",
            "    Aliases: ols\n",
            "  OnlineGradientDescent: Stochastic Gradient Descent (Regression)\n",
            "    Aliases: ogd, sgdr, stochasticgradientdescentregression\n",
            "  OVA: One-vs-All\n",
            "  pcaAnomaly: PCA Anomaly Detector\n",
            "    Aliases: pcaAnom\n",
            "  PKPD: Pairwise coupling (PKPD)\n",
            "  PoissonRegression: Poisson Regression\n",
            "    Aliases: PoissonRegressionNew, Poisson, PR\n",
            "  PriorPredictor: Prior Predictor\n",
            "    Aliases: prior, constant\n",
            "  RandomPredictor: Random Predictor\n",
            "    Aliases: random\n",
            "  RegressionGamTrainer: Generalized Additive Model for Regression\n",
            "    Aliases: gamr\n",
            "  SDCA: Fast Linear (SA-SDCA)\n",
            "    Aliases: LinearClassifier, lc, sasdca\n",
            "  SDCAMC: Fast Linear Multi-class Classification (SA-SDCA)\n",
            "    Aliases: sasdcamc\n",
            "  SDCAR: Fast Linear Regression (SA-SDCA)\n",
            "    Aliases: sasdcar\n"
          ]
        }
      ],
      "source": [
        "%%maml\n",
        "\n",
        "? kind=trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## With Iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pandas import DataFrame\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "df = DataFrame(X, columns=['Slength', 'Swidth', 'Plength', 'Pwidth'])\n",
        "df[\"Label\"] = y\n",
        "df = df[[\"Label\"] + ['Slength', 'Swidth', 'Plength', 'Pwidth']]\n",
        "dftrain, dftest = train_test_split(df)\n",
        "dftrain.to_csv(\"iris_data_id_train.txt\", sep=',', index=False)\n",
        "dftest.to_csv(\"iris_data_id_test.txt\", sep=',', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "maml.exe TrainTest test=iris_data_id_test.txt tr=ova{p=lr} dout=prediction.txt loader=text{col=Label:U4[0-2]:0 col=Slength:R4:1 col=Swidth:R4:2 col=Plength:R4:3 col=Pwidth:R4:4 sep=, header=+} data=iris_data_id_train.txt out=model.zip xf=Concat{col=Features:Slength,Swidth}\n",
            "Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.\n",
            "Training learner 0\n",
            "LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, add 'numThreads=1' to the trainer arguments and 'cache=-' to the command line arguments to turn off multi-threading.\n",
            "Beginning optimization\n",
            "num vars: 3\n",
            "improvement criterion: Mean Improvement\n",
            "L1 regularization selected 3 of 3 weights.\n",
            "Not training a calibrator because it is not needed.\n",
            "Training learner 1\n",
            "LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, add 'numThreads=1' to the trainer arguments and 'cache=-' to the command line arguments to turn off multi-threading.\n",
            "Beginning optimization\n",
            "num vars: 3\n",
            "improvement criterion: Mean Improvement\n",
            "L1 regularization selected 2 of 3 weights.\n",
            "Not training a calibrator because it is not needed.\n",
            "Training learner 2\n",
            "LBFGS multi-threading will attempt to load dataset into memory. In case of out-of-memory issues, add 'numThreads=1' to the trainer arguments and 'cache=-' to the command line arguments to turn off multi-threading.\n",
            "Beginning optimization\n",
            "num vars: 3\n",
            "improvement criterion: Mean Improvement\n",
            "L1 regularization selected 2 of 3 weights.\n",
            "Not training a calibrator because it is not needed.\n",
            "Not training a calibrator because it is not needed.\n",
            "\n",
            "Confusion table\n",
            "          ||========================\n",
            "PREDICTED ||     0 |     1 |     2 | Recall\n",
            "TRUTH     ||========================\n",
            "        0 ||    14 |     1 |     0 | 0.9333\n",
            "        1 ||     0 |     4 |     9 | 0.3077\n",
            "        2 ||     0 |     1 |     9 | 0.9000\n",
            "          ||========================\n",
            "Precision ||1.0000 |0.6667 |0.5000 |\n",
            "Accuracy(micro-avg): 0.710526\n",
            "Accuracy(macro-avg): 0.713675\n",
            "Log-loss:           0.974880\n",
            "Log-loss reduction: 10.165310\n",
            "\n",
            "OVERALL RESULTS\n",
            "---------------------------------------\n",
            "Accuracy(micro-avg): 0.710526 (0.0000)\n",
            "Accuracy(macro-avg): 0.713675 (0.0000)\n",
            "Log-loss:           0.974880 (0.0000)\n",
            "Log-loss reduction: 10.165310 (0.0000)\n",
            "\n",
            "---------------------------------------\n",
            "Physical memory usage(MB): 178\n",
            "Virtual memory usage(MB): 4934\n",
            "21/05/2018 22:19:40\t Time elapsed(s): 0.22\n",
            "\n",
            "[1] 'Normalize' started.\n",
            "[1] (00:00.00)\t112 examples\n",
            "[1] 'Normalize' finished in 00:00:00.0029926.\n",
            "[2] 'LBFGS data prep' started.\n",
            "[2] 'LBFGS data prep' finished in 00:00:00.\n",
            "[3] 'LBFGS Optimizer' started.\n",
            "[3] (00:00.00)\t0 iterations\tLoss: 0.693147242069244\n",
            "[3] (00:00.00)\t1 iterations\tLoss: 0.65739893913269\tImprovement: 0.03575\n",
            "[3] (00:00.00)\t2 iterations\tLoss: 0.616447865962982\tImprovement: 0.03991\n",
            "[3] (00:00.00)\t3 iterations\tLoss: 0.610415697097778\tImprovement: 0.0141\n",
            "[3] (00:00.00)\t4 iterations\tLoss: 0.606947898864746\tImprovement: 0.006094\n",
            "[3] (00:00.00)\t5 iterations\tLoss: 0.594254434108734\tImprovement: 0.01105\n",
            "[3] (00:00.00)\t6 iterations\tLoss: 0.579987704753876\tImprovement: 0.01346\n",
            "[3] (00:00.00)\t7 iterations\tLoss: 0.579895257949829\tImprovement: 0.003434\n",
            "[3] (00:00.00)\t8 iterations\tLoss: 0.579882442951202\tImprovement: 0.0008682\n",
            "[3] (00:00.00)\t9 iterations\tLoss: 0.579871773719788\tImprovement: 0.000225\n",
            "[3] (00:00.00)\t10 iterations\tLoss: 0.579851090908051\tImprovement: 7.177E-05\n",
            "[3] (00:00.00)\t11 iterations\tLoss: 0.579840779304504\tImprovement: 2.568E-05\n",
            "[3] (00:00.00)\t12 iterations\tLoss: 0.57984071969986\tImprovement: 6.464E-06\n",
            "[3] (00:00.00)\t13 iterations\tLoss: 0.57984071969986\tImprovement: 1.616E-06\n",
            "[3] (00:00.00)\t14 iterations\tLoss: 0.57984071969986\tImprovement: 4.04E-07\n",
            "[3] (00:00.00)\t15 iterations\tLoss: 0.579840660095215\tImprovement: 1.457E-07\n",
            "[3] (00:00.00)\t16 iterations\tLoss: 0.579840660095215\tImprovement: 3.643E-08\n",
            "[3] 'LBFGS Optimizer' finished in 00:00:00.0009968.\n",
            "[4] 'LBFGS data prep #2' started.\n",
            "[4] 'LBFGS data prep #2' finished in 00:00:00.\n",
            "[5] 'LBFGS Optimizer #2' started.\n",
            "[5] (00:00.00)\t0 iterations\tLoss: 0.693147242069244\n",
            "[5] (00:00.00)\t1 iterations\tLoss: 0.688190460205078\tImprovement: 0.004957\n",
            "[5] (00:00.00)\t2 iterations\tLoss: 0.635145127773285\tImprovement: 0.04343\n",
            "[5] (00:00.00)\t3 iterations\tLoss: 0.633720636367798\tImprovement: 0.01143\n",
            "[5] (00:00.00)\t4 iterations\tLoss: 0.633012175559998\tImprovement: 0.003356\n",
            "[5] (00:00.00)\t5 iterations\tLoss: 0.630553364753723\tImprovement: 0.002682\n",
            "[5] (00:00.00)\t6 iterations\tLoss: 0.630473375320435\tImprovement: 0.0007301\n",
            "[5] (00:00.00)\t7 iterations\tLoss: 0.630366265773773\tImprovement: 0.0002628\n",
            "[5] (00:00.00)\t8 iterations\tLoss: 0.630204379558563\tImprovement: 0.0001871\n",
            "[5] (00:00.00)\t9 iterations\tLoss: 0.630147874355316\tImprovement: 8.916E-05\n",
            "[5] (00:00.00)\t10 iterations\tLoss: 0.629692494869232\tImprovement: 0.0003638\n",
            "[5] (00:00.00)\t11 iterations\tLoss: 0.629132270812988\tImprovement: 0.0005111\n",
            "[5] (00:00.00)\t12 iterations\tLoss: 0.629067838191986\tImprovement: 0.0001761\n",
            "[5] (00:00.00)\t13 iterations\tLoss: 0.629005253314972\tImprovement: 9.097E-05\n",
            "[5] (00:00.00)\t14 iterations\tLoss: 0.628998935222626\tImprovement: 2.748E-05\n",
            "[5] (00:00.00)\t15 iterations\tLoss: 0.628998458385468\tImprovement: 7.228E-06\n",
            "[5] (00:00.00)\t16 iterations\tLoss: 0.628998398780823\tImprovement: 1.852E-06\n",
            "[5] (00:00.00)\t17 iterations\tLoss: 0.628998398780823\tImprovement: 4.629E-07\n",
            "[5] (00:00.00)\t18 iterations\tLoss: 0.628998398780823\tImprovement: 1.157E-07\n",
            "[5] (00:00.00)\t19 iterations\tLoss: 0.628998398780823\tImprovement: 2.893E-08\n",
            "[5] 'LBFGS Optimizer #2' finished in 00:00:00.0009983.\n",
            "[6] 'LBFGS data prep #3' started.\n",
            "[6] 'LBFGS data prep #3' finished in 00:00:00.\n",
            "[7] 'LBFGS Optimizer #3' started.\n",
            "[7] (00:00.00)\t0 iterations\tLoss: 0.693147242069244\n",
            "[7] (00:00.00)\t1 iterations\tLoss: 0.662655651569366\tImprovement: 0.03049\n",
            "[7] (00:00.00)\t2 iterations\tLoss: 0.656234204769135\tImprovement: 0.01124\n",
            "[7] (00:00.00)\t3 iterations\tLoss: 0.653100967407227\tImprovement: 0.005062\n",
            "[7] (00:00.00)\t4 iterations\tLoss: 0.65029513835907\tImprovement: 0.003363\n",
            "[7] (00:00.00)\t5 iterations\tLoss: 0.64232873916626\tImprovement: 0.006819\n",
            "[7] (00:00.00)\t6 iterations\tLoss: 0.634611964225769\tImprovement: 0.007492\n",
            "[7] (00:00.00)\t7 iterations\tLoss: 0.629342436790466\tImprovement: 0.005825\n",
            "[7] (00:00.00)\t8 iterations\tLoss: 0.628150284290314\tImprovement: 0.00235\n",
            "[7] (00:00.00)\t9 iterations\tLoss: 0.627827405929565\tImprovement: 0.0008297\n",
            "[7] (00:00.00)\t10 iterations\tLoss: 0.627818048000336\tImprovement: 0.0002145\n",
            "[7] (00:00.00)\t11 iterations\tLoss: 0.627814471721649\tImprovement: 5.63E-05\n",
            "[7] (00:00.00)\t12 iterations\tLoss: 0.627812206745148\tImprovement: 1.577E-05\n",
            "[7] (00:00.00)\t13 iterations\tLoss: 0.627810895442963\tImprovement: 4.927E-06\n",
            "[7] (00:00.00)\t14 iterations\tLoss: 0.62781023979187\tImprovement: 1.723E-06\n",
            "[7] (00:00.00)\t15 iterations\tLoss: 0.627809941768646\tImprovement: 6.544E-07\n",
            "[7] (00:00.00)\t16 iterations\tLoss: 0.627809882164001\tImprovement: 2.083E-07\n",
            "[7] (00:00.00)\t17 iterations\tLoss: 0.627807021141052\tImprovement: 2.198E-06\n",
            "[7] (00:00.00)\t18 iterations\tLoss: 0.627806782722473\tImprovement: 7.283E-07\n",
            "[7] (00:00.00)\t19 iterations\tLoss: 0.627806782722473\tImprovement: 1.821E-07\n",
            "[7] (00:00.00)\t20 iterations\tLoss: 0.627805888652802\tImprovement: 7.161E-07\n",
            "[7] (00:00.00)\t21 iterations\tLoss: 0.627805888652802\tImprovement: 1.79E-07\n",
            "[7] (00:00.00)\t22 iterations\tLoss: 0.627805888652802\tImprovement: 4.475E-08\n",
            "[7] 'LBFGS Optimizer #3' finished in 00:00:00.0019951.\n",
            "[8] 'Saving model' started.\n",
            "[8] 'Saving model' finished in 00:00:00.0837745.\n"
          ]
        }
      ],
      "source": [
        "%%maml\n",
        "\n",
        "traintest\n",
        "data=iris_data_id_train.txt\n",
        "test=iris_data_id_test.txt\n",
        "loader=text{col=Label:U4[0-2]:0 col=Slength:R4:1 col=Swidth:R4:2 col=Plength:R4:3 col=Pwidth:R4:4 sep=, header=+}\n",
        "xf=Concat{col=Features:Slength,Swidth}\n",
        "tr=ova{p=lr}\n",
        "out=model.zip\n",
        "dout=prediction.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Instance</th>\n",
              "      <th>Label</th>\n",
              "      <th>Assigned</th>\n",
              "      <th>Log-loss</th>\n",
              "      <th>#1 Score</th>\n",
              "      <th>#2 Score</th>\n",
              "      <th>#3 Score</th>\n",
              "      <th>#1 Class</th>\n",
              "      <th>#2 Class</th>\n",
              "      <th>#3 Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.947795</td>\n",
              "      <td>0.387595</td>\n",
              "      <td>0.308399</td>\n",
              "      <td>0.304006</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.935981</td>\n",
              "      <td>0.392201</td>\n",
              "      <td>0.350858</td>\n",
              "      <td>0.256941</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.997204</td>\n",
              "      <td>0.368910</td>\n",
              "      <td>0.341771</td>\n",
              "      <td>0.289320</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.895535</td>\n",
              "      <td>0.408389</td>\n",
              "      <td>0.328206</td>\n",
              "      <td>0.263405</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.095279</td>\n",
              "      <td>0.372632</td>\n",
              "      <td>0.334446</td>\n",
              "      <td>0.292921</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Instance  Label  Assigned  Log-loss  #1 Score  #2 Score  #3 Score  \\\n",
              "0         0      0         0  0.947795  0.387595  0.308399  0.304006   \n",
              "1         1      2         2  0.935981  0.392201  0.350858  0.256941   \n",
              "2         2      0         0  0.997204  0.368910  0.341771  0.289320   \n",
              "3         3      2         2  0.895535  0.408389  0.328206  0.263405   \n",
              "4         4      1         2  1.095279  0.372632  0.334446  0.292921   \n",
              "\n",
              "   #1 Class  #2 Class  #3 Class  \n",
              "0         0         2         1  \n",
              "1         2         1         0  \n",
              "2         0         2         1  \n",
              "3         2         1         0  \n",
              "4         2         1         0  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pandas import read_csv\n",
        "pred = read_csv(\"prediction.txt\", sep=\"\\t\")\n",
        "pred.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}